{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercicio Coh - Piah.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPE1F2RQAwxuE5aJoQzsM39",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PedroOlavo/Projetos---Python-Basico/blob/main/Exercicio_Coh_Piah.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qno85KYSDjDb"
      },
      "source": [
        "# Coh-Piah\r\n",
        "\r\n",
        "Exercício final do curso Introdução a Ciência da Computação com Python do Coursera.\r\n",
        "\r\n",
        "Espero que sirva de ajuda para alguém.\r\n",
        "\r\n",
        "Se está aqui, conecte-se comigo no [LinkedIn](https://www.linkedin.com/in/pedro-olavo-sousa-201b9a1b0/).\r\n",
        "\r\n",
        "Conheça também meu [Medium](https://medium.com/@pedroolavosousa), lá publico artigos diversos sobre ciência de dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja3Of7QOfz13"
      },
      "source": [
        "#parte que eles fornecem\r\n",
        "import re\r\n",
        "\r\n",
        "def le_assinatura():\r\n",
        "    '''A funcao le os valores dos tracos linguisticos do modelo e devolve uma assinatura a ser comparada com os textos fornecidos'''\r\n",
        "    print(\"Bem-vindo ao detector automático de COH-PIAH.\")\r\n",
        "    print(\"Informe a assinatura típica de um aluno infectado:\")\r\n",
        "\r\n",
        "    wal = float(input(\"Entre o tamanho médio de palavra:\"))\r\n",
        "    ttr = float(input(\"Entre a relação Type-Token:\"))\r\n",
        "    hlr = float(input(\"Entre a Razão Hapax Legomana:\"))\r\n",
        "    sal = float(input(\"Entre o tamanho médio de sentença:\"))\r\n",
        "    sac = float(input(\"Entre a complexidade média da sentença:\"))\r\n",
        "    pal = float(input(\"Entre o tamanho medio de frase:\"))\r\n",
        "\r\n",
        "    return [wal, ttr, hlr, sal, sac, pal]\r\n",
        "\r\n",
        "def le_textos():\r\n",
        "    '''A funcao le todos os textos a serem comparados e devolve uma lista contendo cada texto como um elemento'''\r\n",
        "    i = 1\r\n",
        "    textos = []\r\n",
        "    texto = input(\"Digite o texto \" + str(i) +\" (aperte enter para sair):\")\r\n",
        "    while texto:\r\n",
        "        textos.append(texto)\r\n",
        "        i += 1\r\n",
        "        texto = input(\"Digite o texto \" + str(i) +\" (aperte enter para sair):\")\r\n",
        "\r\n",
        "    return textos\r\n",
        "\r\n",
        "def separa_sentencas(texto):\r\n",
        "    '''A funcao recebe um texto e devolve uma lista das sentencas dentro do texto'''\r\n",
        "    sentencas = re.split(r'[.!?]+', texto)\r\n",
        "    if sentencas[-1] == '':\r\n",
        "        del sentencas[-1]\r\n",
        "    return sentencas\r\n",
        "\r\n",
        "def separa_frases(sentenca):\r\n",
        "    '''A funcao recebe uma sentenca e devolve uma lista das frases dentro da sentenca'''\r\n",
        "    return re.split(r'[,:;]+', sentenca)\r\n",
        "\r\n",
        "def separa_palavras(frase):\r\n",
        "    '''A funcao recebe uma frase e devolve uma lista das palavras dentro da frase'''\r\n",
        "    return frase.split()\r\n",
        "\r\n",
        "def n_palavras_unicas(lista_palavras):\r\n",
        "    '''Essa funcao recebe uma lista de palavras e devolve o numero de palavras que aparecem uma unica vez'''\r\n",
        "    freq = dict()\r\n",
        "    unicas = 0\r\n",
        "    for palavra in lista_palavras:\r\n",
        "        p = palavra.lower()\r\n",
        "        if p in freq:\r\n",
        "            if freq[p] == 1:\r\n",
        "                unicas -= 1\r\n",
        "            freq[p] += 1\r\n",
        "        else:\r\n",
        "            freq[p] = 1\r\n",
        "            unicas += 1\r\n",
        "\r\n",
        "    return unicas\r\n",
        "\r\n",
        "def n_palavras_diferentes(lista_palavras):\r\n",
        "    '''Essa funcao recebe uma lista de palavras e devolve o numero de palavras diferentes utilizadas'''\r\n",
        "    freq = dict()\r\n",
        "    for palavra in lista_palavras:\r\n",
        "        p = palavra.lower()\r\n",
        "        if p in freq:\r\n",
        "            freq[p] += 1\r\n",
        "        else:\r\n",
        "            freq[p] = 1\r\n",
        "\r\n",
        "    return len(freq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgnsGx22gCuP"
      },
      "source": [
        "def calcula_assinatura(texto):\r\n",
        "    '''IMPLEMENTAR. Essa funcao recebe um texto e deve devolver a assinatura do texto.'''\r\n",
        "    lista_plv = []\r\n",
        "    lista_fr = []\r\n",
        "    sentencas = separa_sentencas(texto)\r\n",
        "\r\n",
        "    #aqui ja vou ter as sentenças tudo numa lista, cada sentenca numa posição da lista\r\n",
        "    #agora preciso separar as frases das sentenças\r\n",
        "\r\n",
        "    for sentenca in sentencas:\r\n",
        "      #sentenca é um elemento da lista sentencas\r\n",
        "      #por exemplo na primeira rodada sentenca=sentencas[0]\r\n",
        "\r\n",
        "      lista_fr += separa_frases(sentenca)\r\n",
        "\r\n",
        "      #agora tenho uma lista com as frases e preciso guardar elas na lista_fr, que é a lista das frases\r\n",
        "      #agora eu tenho uma lista com as frases, cada slot é uma frase, devo contar as palavras únicas naquela frase\r\n",
        "\r\n",
        "    for frase in lista_fr:\r\n",
        "      lista_plv += separa_palavras(frase)\r\n",
        "\r\n",
        "      #agora tenho uma lista com as palavras\r\n",
        "\r\n",
        "    palavras_unicas = n_palavras_unicas(lista_plv)\r\n",
        "    palavras_diferentes = n_palavras_diferentes(lista_plv)\r\n",
        "\r\n",
        "    #Tamanho médio de palavra é a soma de todos os caracteres das palavras dividida pelo número total de palavras\r\n",
        "\r\n",
        "    tamanho_total = 0\r\n",
        "    for palavra in lista_plv:\r\n",
        "      tamanho_total = len(palavra) + tamanho_total\r\n",
        "      #aqui lê o tamanho da palavra atual e soma com as anteriores\r\n",
        "    \r\n",
        "    n_total_plv = len(lista_plv)\r\n",
        "\r\n",
        "    tam_medio_plv = tamanho_total/n_total_plv\r\n",
        "\r\n",
        "    #type_token é número de palavras diferentes dividido pelo número total de palavras\r\n",
        "\r\n",
        "    tt = palavras_diferentes/n_total_plv\r\n",
        "\r\n",
        "    #Razão Hapax Legomana é o número de palavras que aparecem uma única vez dividido pelo total de palavras\r\n",
        "\r\n",
        "    r_hapax = palavras_unicas/n_total_plv\r\n",
        "\r\n",
        "    #Tamanho médio de sentença é a soma dos números de caracteres em todas as sentenças dividida pelo número de sentenças\r\n",
        "\r\n",
        "    #aqui tem um pulo do gato, pq o número total de caracteres é o tamanho_total, pq ele ja contou as letras\r\n",
        "\r\n",
        "    #de todas as palvras que compõe as frases que por sua vez compõe as sentenças\r\n",
        "\r\n",
        "    n_sent = len(sentencas)\r\n",
        "\r\n",
        "    tam_medio_sent = tamanho_total/n_sent\r\n",
        "\r\n",
        "    #Complexidade de sentença é o número total de frases divido pelo número de sentenças.\r\n",
        "\r\n",
        "    n_total_fra = len(lista_fr)\r\n",
        "\r\n",
        "    comp = n_total_fra/n_sent\r\n",
        "\r\n",
        "    #tamanho médio da frase é o tamanho_total dividido pelo número de frases\r\n",
        "\r\n",
        "    tam_medio_fr = tamanho_total/n_total_fra\r\n",
        "\r\n",
        "    assinatura = [tam_medio_plv, tt, r_hapax, tam_medio_sent, comp, tam_medio_fr]\r\n",
        "\r\n",
        "    return assinatura\r\n",
        "def compara_assinatura(as_a, as_b):\r\n",
        "    '''IMPLEMENTAR. Essa funcao recebe duas assinaturas de texto e deve devolver o grau de similaridade nas assinaturas.'''\r\n",
        "    soma = 0\r\n",
        "    for i in range(len(as_a)):\r\n",
        "      soma = soma + abs(as_a[i] - as_b[i])\r\n",
        "    \r\n",
        "    similaridade = soma / 6\r\n",
        "    return similaridade\r\n",
        "\r\n",
        "\r\n",
        "def avalia_textos(textos, ass_cp):\r\n",
        "    '''IMPLEMENTAR. Essa funcao recebe uma lista de textos e uma assinatura ass_cp e deve devolver o numero (1 a n) do texto com maior probabilidade de ter sido infectado por COH-PIAH.'''\r\n",
        "    textos = le_textos()\r\n",
        "    assinatura = le_assinatura()\r\n",
        "    assinaturas_b = []\r\n",
        "    for i in range(len(textos)):\r\n",
        "      assinaturas_b[i] = calcula_assinatura(textos[i])\r\n",
        "    \r\n",
        "    #preciso pegar a menor similaridade, pois essa me dará o texto mais provável de ser plágio\r\n",
        "    simi = []\r\n",
        "    for i in range(len(assinaturas_b)):\r\n",
        "      simi[i] = compara_assinatura(assinatura, assinaturas_b[i])\r\n",
        "    \r\n",
        "    mais_provavel = simi.index(min(simi))\r\n",
        "    #nessa linha eu pego o index do menor coeficiente de similaridade, pq ai eu pego o texto com o mesmo index e retorno ele\r\n",
        "    #na verdade posso devolver só o número do texto, como é dito no enunciado\r\n",
        "    return mais_provavel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvpubrlwUOtc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}